{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'../input/train.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-54d0dc49baa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixture\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianMixture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'../input/train.csv' does not exist"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "\n",
    "print(len(train))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 and 2 - Build first QDA model and predict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # search optimal reg_param\n",
    "\n",
    "# # INITIALIZE VARIABLES\n",
    "# cols = [c for c in train.columns if c not in ['id', 'target']]\n",
    "# cols.remove('wheezy-copper-turtle-magic')\n",
    "# oof = np.zeros(len(train))\n",
    "# preds = np.zeros(len(test))\n",
    "\n",
    "# scores = []\n",
    "# cand = np.arange(0.1, 1.0, 0.1)\n",
    "\n",
    "# for reg in cand:\n",
    "\n",
    "#     # BUILD 512 SEPARATE MODELS\n",
    "#     for i in range(512):\n",
    "#         # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n",
    "#         train2 = train[train['wheezy-copper-turtle-magic']==i]\n",
    "#         test2 = test[test['wheezy-copper-turtle-magic']==i]\n",
    "#         idx1 = train2.index; idx2 = test2.index\n",
    "#         train2.reset_index(drop=True,inplace=True)\n",
    "\n",
    "#         # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n",
    "#         sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n",
    "#         train3 = sel.transform(train2[cols])\n",
    "#         test3 = sel.transform(test2[cols])\n",
    "        \n",
    "        \n",
    "# #         pca = PCA(n_components=2)\n",
    "# #         trans = pca.fit_transform(train3)\n",
    "# #         fig = plt.figure()\n",
    "# #         label1 = np.where(train2[\"target\"].values==1)\n",
    "# #         label0 = np.where(train2[\"target\"].values==0)\n",
    "        \n",
    "# #         plt.scatter(trans[label1,0], trans[label1,1])\n",
    "# #         plt.scatter(trans[label0,0], trans[label0,1])\n",
    "# #         plt.show()\n",
    "# #         plt.close()\n",
    "        \n",
    "\n",
    "#         # STRATIFIED K-FOLD\n",
    "#         skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n",
    "#         for train_index, test_index in skf.split(train3, train2['target']):\n",
    "\n",
    "#             # MODEL AND PREDICT WITH QDA\n",
    "#             clf = QuadraticDiscriminantAnalysis(reg_param=reg)\n",
    "#             clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "#             oof[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n",
    "#             preds[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits\n",
    "\n",
    "#         #if i%64==0: print(i)\n",
    "\n",
    "#     # PRINT CV AUC\n",
    "#     auc = roc_auc_score(train['target'],oof)\n",
    "#     scores.append(auc)\n",
    "#     print('reg:{} QDA scores CV = {}'.format(reg, round(auc,5)))\n",
    "    \n",
    "# best_reg = cand[np.argmax(scores)]\n",
    "# # print(\"best reg:{} score;{}\".format(best_reg, np.max(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_reg=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [c for c in train.columns if c not in ['id', 'target']]\n",
    "\n",
    "def low_high_var_feats(df):\n",
    "    low_vars = []\n",
    "    high_vars = []\n",
    "    \n",
    "    for feat in cols:\n",
    "        if df[feat].var() < 3.0:\n",
    "            low_vars.append(feat)\n",
    "        else:\n",
    "            high_vars.append(feat)\n",
    "    return low_vars, high_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(512):\n",
    "#     # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n",
    "#     train2 = train[train['wheezy-copper-turtle-magic']==i]\n",
    "#     test2 = test[test['wheezy-copper-turtle-magic']==i]\n",
    "#     idx1 = train2.index; idx2 = test2.index\n",
    "#     train2.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "#     var = []\n",
    "#     for feat in cols:\n",
    "#         var.append(train2[feat].var())\n",
    "#     plt.hist(var, bins=30)\n",
    "#     plt.show()\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import GraphicalLasso\n",
    "\n",
    "def get_mean_cov(x,y):\n",
    "    model = GraphicalLasso()\n",
    "    ones = (y==1).astype(bool)\n",
    "    x2 = x[ones]\n",
    "    model.fit(x2)\n",
    "    p1 = model.precision_\n",
    "    m1 = model.location_\n",
    "    \n",
    "    onesb = (y==0).astype(bool)\n",
    "    x2b = x[onesb]\n",
    "    model.fit(x2b)\n",
    "    p2 = model.precision_\n",
    "    m2 = model.location_\n",
    "    \n",
    "    ms = np.stack([m1,m1,m1,m2,m2,m2])\n",
    "    ps = np.stack([p1,p1,p1,p2,p2,p2])\n",
    "    return ms,ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make initial means, precisions for six clusters.\n",
    "\n",
    "def cluster_analysis(X_label0, X_label1):\n",
    "    gmm_label0 = GaussianMixture(n_components=3, covariance_type=\"full\", init_params=\"kmeans\").fit(X_label0)\n",
    "    gmm_label1 = GaussianMixture(n_components=3, covariance_type=\"full\", init_params=\"kmeans\").fit(X_label1)\n",
    "    \n",
    "    ms = np.vstack([gmm_label0.means_, gmm_label1.means_])\n",
    "    ps = np.vstack([gmm_label0.precisions_, gmm_label1.precisions_])\n",
    "    return ms, ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# # INITIALIZE VARIABLES\n",
    "# cols = [c for c in train.columns if c not in ['id', 'target']]\n",
    "# cols.remove('wheezy-copper-turtle-magic')\n",
    "# oof_qda = np.zeros(len(train))\n",
    "# preds_qda = np.zeros(len(test))\n",
    "\n",
    "# # BUILD 512 SEPARATE MODELS\n",
    "# for i in range(512):\n",
    "#     # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n",
    "#     train2 = train[train['wheezy-copper-turtle-magic']==i]\n",
    "#     test2 = test[test['wheezy-copper-turtle-magic']==i]\n",
    "#     idx1 = train2.index; idx2 = test2.index\n",
    "#     train2.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "#     low, high = low_high_var_feats(train2)\n",
    "    \n",
    "#     # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n",
    "# #     sel = VarianceThreshold(threshold=2.5).fit(train2[cols])\n",
    "# #     train3 = sel.transform(train2[cols])\n",
    "# #     test3 = sel.transform(test2[cols])\n",
    "\n",
    "#     train3 = train2[high].values\n",
    "#     test3 = test2[high].values\n",
    "\n",
    "#     # STRATIFIED K-FOLD\n",
    "#     skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n",
    "#     for train_index, test_index in skf.split(train3, train2['target']):\n",
    "\n",
    "#         # MODEL AND PREDICT WITH QDA\n",
    "#         clf_qda = QuadraticDiscriminantAnalysis(reg_param=best_reg)\n",
    "#         clf_qda.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "#         oof_qda[idx1[test_index]] = clf_qda.predict_proba(train3[test_index,:])[:,1]\n",
    "#         preds_qda[idx2] += clf_qda.predict_proba(test3)[:,1] / skf.n_splits\n",
    "\n",
    "#     #if i%64==0: print(i)\n",
    "\n",
    "# # PRINT CV AUC\n",
    "# auc = roc_auc_score(train['target'],oof_qda)\n",
    "# print('QDA scores CV = {}'.format(round(auc,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b73194f50a674e76ab7f5cbd17448bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=512), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMM score:0.9634714407980581 QDA score:0.9568700629972078\n",
      "GMM score:0.9711443705346144 QDA score:0.9625754496181326\n",
      "GMM score:0.9734388268338885 QDA score:0.9680416748317983\n",
      "GMM score:0.9873783181245412 QDA score:0.9754766883143859\n",
      "GMM score:0.974164225077004 QDA score:0.9639621365787695\n",
      "GMM score:0.9728403430693509 QDA score:0.9646025523888118\n",
      "GMM score:0.9878141546722351 QDA score:0.9827876799164741\n",
      "GMM score:0.9647544056992877 QDA score:0.954107299087614\n",
      "GMM score:0.982896379525593 QDA score:0.9721818315341118\n",
      "GMM score:0.9727244031221303 QDA score:0.9703856749311295\n",
      "GMM score:0.9583978577881016 QDA score:0.9733352690669763\n",
      "GMM score:0.98375 QDA score:0.9751379310344828\n",
      "GMM score:0.9805024798764127 QDA score:0.9737539637368893\n",
      "GMM score:0.9644765957446809 QDA score:0.9733872340425531\n",
      "GMM score:0.9848106215150279 QDA score:0.979812661498708\n",
      "GMM score:0.981323717226354 QDA score:0.9744572158365262\n",
      "GMM score:0.969677680256418 QDA score:0.9739088757750951\n",
      "GMM score:0.9868558202274749 QDA score:0.9754667525062081\n",
      "GMM score:0.9746588112461779 QDA score:0.9782161234991423\n",
      "GMM score:0.9795922793320321 QDA score:0.9765922070411335\n",
      "GMM score:0.975816064551623 QDA score:0.9643239195549849\n",
      "GMM score:0.9796154933559513 QDA score:0.9645320893412497\n",
      "GMM score:0.9784365454040544 QDA score:0.9816162177173008\n",
      "GMM score:0.9787065319548872 QDA score:0.9709380874060151\n",
      "GMM score:0.971808144677784 QDA score:0.9666644825213773\n",
      "GMM score:0.975080680041255 QDA score:0.9625295272315934\n",
      "GMM score:0.9592349433911704 QDA score:0.9638574395390902\n",
      "GMM score:0.9412317558602389 QDA score:0.9516964680609086\n",
      "GMM score:0.9680755146202076 QDA score:0.9648088553514953\n",
      "GMM score:0.9784596774193549 QDA score:0.9735967741935485\n",
      "GMM score:0.9732901139420317 QDA score:0.9724060809381327\n",
      "GMM score:0.9685907532660057 QDA score:0.9585688254733005\n",
      "GMM score:0.9873768578587856 QDA score:0.9725912195791714\n",
      "GMM score:0.9722158438576349 QDA score:0.9655568312284729\n",
      "GMM score:0.9804221049708415 QDA score:0.9763223665940748\n",
      "GMM score:0.9793203823044114 QDA score:0.9630926808007222\n",
      "GMM score:0.9607028434120946 QDA score:0.9614036844213054\n",
      "GMM score:0.9826494948308271 QDA score:0.9746828007518797\n",
      "GMM score:0.9728843431279073 QDA score:0.9762142093554073\n",
      "GMM score:0.9773512655272252 QDA score:0.9703075869368948\n",
      "GMM score:0.9705325366506676 QDA score:0.9653981780781664\n",
      "GMM score:0.9692826655651934 QDA score:0.9658749827894809\n",
      "GMM score:0.9527750730282376 QDA score:0.9676511954992969\n",
      "GMM score:0.9716658524670249 QDA score:0.9561664520140338\n",
      "GMM score:0.9670918041171206 QDA score:0.9690017261219793\n",
      "GMM score:0.9719052904180541 QDA score:0.96488346281909\n",
      "GMM score:0.9792636682186915 QDA score:0.9637274196387142\n",
      "GMM score:0.9705167533603047 QDA score:0.9671749729545489\n",
      "GMM score:0.9685220018239854 QDA score:0.9664700182398541\n",
      "GMM score:0.965491452991453 QDA score:0.9646062271062271\n",
      "GMM score:0.9742619926199262 QDA score:0.9678110173958884\n",
      "GMM score:0.9766756131192751 QDA score:0.9686730522998129\n",
      "GMM score:0.9738504738504737 QDA score:0.9591244136698681\n",
      "GMM score:0.9803872971811904 QDA score:0.9675324675324676\n",
      "GMM score:0.9694417298773015 QDA score:0.9655172413793104\n",
      "GMM score:0.9741346010993908 QDA score:0.9825508839696924\n",
      "GMM score:0.9788689138576779 QDA score:0.9707340823970037\n",
      "GMM score:0.9843886825497478 QDA score:0.9757073406407585\n",
      "GMM score:0.9868285123966943 QDA score:0.976200538442274\n",
      "GMM score:0.9699284944656676 QDA score:0.9672021419009372\n",
      "GMM score:0.9678655442292613 QDA score:0.9722004408871002\n",
      "GMM score:0.975238185717 QDA score:0.9610081159577644\n",
      "GMM score:0.9710457573889819 QDA score:0.9687344075606822\n",
      "GMM score:0.9755142589995325 QDA score:0.9672159887798035\n",
      "GMM score:0.9832617257429287 QDA score:0.9821256437797791\n",
      "GMM score:0.9822946790052053 QDA score:0.968008964719491\n",
      "GMM score:0.9634876518700864 QDA score:0.9642340983085841\n",
      "GMM score:0.9741024938339271 QDA score:0.9592354069608111\n",
      "GMM score:0.9572733729338841 QDA score:0.9614863119834711\n",
      "GMM score:0.9701663554574775 QDA score:0.9659155208510156\n",
      "GMM score:0.9880915003363984 QDA score:0.9834342528220079\n",
      "GMM score:0.9654458009618941 QDA score:0.9656899741028486\n",
      "GMM score:0.9685941434990865 QDA score:0.955985712639705\n",
      "GMM score:0.9759472115793955 QDA score:0.9747361312957825\n",
      "GMM score:0.9818587270973963 QDA score:0.9576129632180741\n",
      "GMM score:0.9732298783663715 QDA score:0.9612963019700358\n",
      "GMM score:0.9796296296296296 QDA score:0.9650054466230937\n",
      "GMM score:0.9833882611424984 QDA score:0.9759102322661645\n",
      "GMM score:0.9627118391216136 QDA score:0.968813402554004\n",
      "GMM score:0.9709288824383164 QDA score:0.952743105950653\n",
      "GMM score:0.9890293307405608 QDA score:0.975255226057365\n",
      "GMM score:0.9601726335302978 QDA score:0.9484199397520565\n",
      "GMM score:0.967035913464485 QDA score:0.9606162284733714\n",
      "GMM score:0.98147903356099 QDA score:0.9809723140192407\n",
      "GMM score:0.9751897636087616 QDA score:0.96881370635437\n",
      "GMM score:0.963641910739191 QDA score:0.9586820083682008\n",
      "GMM score:0.9883915104503339 QDA score:0.9755103964662788\n",
      "GMM score:0.9406174315582942 QDA score:0.9437291149330145\n",
      "GMM score:0.9707659987071751 QDA score:0.9732385261797026\n",
      "GMM score:0.9595381734969834 QDA score:0.9515438794614997\n",
      "GMM score:0.9756772388351336 QDA score:0.9697997592734435\n",
      "GMM score:0.9765306122448979 QDA score:0.9681083202511774\n",
      "GMM score:0.9709093673965937 QDA score:0.9530261557177615\n",
      "GMM score:0.9610696122059759 QDA score:0.9530514939605849\n",
      "GMM score:0.965076301345075 QDA score:0.9597533023704686\n",
      "GMM score:0.9556461653386454 QDA score:0.9538019795816733\n",
      "GMM score:0.9551044832527597 QDA score:0.9482071713147411\n",
      "GMM score:0.9703912815126049 QDA score:0.9587792148109243\n",
      "GMM score:0.9755688806888069 QDA score:0.9737084870848708\n",
      "GMM score:0.962207916070577 QDA score:0.9571769194086791\n",
      "GMM score:0.9700389105058365 QDA score:0.959662775616083\n",
      "GMM score:0.982857228410588 QDA score:0.9736195951610971\n",
      "GMM score:0.96111310915303 QDA score:0.9567973386081641\n",
      "GMM score:0.9643824758610751 QDA score:0.951614065427295\n",
      "GMM score:0.9641997714592996 QDA score:0.9528937285743093\n",
      "GMM score:0.9733292698174544 QDA score:0.9584114778694675\n",
      "GMM score:0.9858160611298687 QDA score:0.9781425178914719\n",
      "GMM score:0.955080545229244 QDA score:0.9525625139008038\n",
      "GMM score:0.9715773408744052 QDA score:0.9704282251548613\n",
      "GMM score:0.9737972322241985 QDA score:0.9700013014619757\n",
      "GMM score:0.9818135081292977 QDA score:0.968012981170876\n",
      "GMM score:0.9812078815768853 QDA score:0.9728518713758567\n",
      "GMM score:0.9780618056480125 QDA score:0.9727066968446278\n",
      "GMM score:0.9796708300806661 QDA score:0.9740518475149623\n",
      "GMM score:0.9663900350087521 QDA score:0.9591772943235808\n",
      "GMM score:0.9743053429922117 QDA score:0.9611859334081557\n",
      "GMM score:0.9803897251461082 QDA score:0.9717937588168726\n",
      "GMM score:0.979456271669745 QDA score:0.9703590291954246\n",
      "GMM score:0.9645011330311918 QDA score:0.966275659824047\n",
      "GMM score:0.9753467741935483 QDA score:0.9658709677419355\n",
      "GMM score:0.9719471712091639 QDA score:0.953525481200758\n",
      "GMM score:0.9683521731714502 QDA score:0.9643516149540245\n",
      "GMM score:0.9793661650706795 QDA score:0.9560267517859858\n",
      "GMM score:0.978504990050749 QDA score:0.9761217973437813\n",
      "GMM score:0.9862592507820249 QDA score:0.9815671015487907\n",
      "GMM score:0.9448871605253092 QDA score:0.9409505291342599\n",
      "GMM score:0.9715974896975247 QDA score:0.9693753871845289\n",
      "GMM score:0.9913204325554923 QDA score:0.971976754635593\n",
      "GMM score:0.9727358490566037 QDA score:0.9670101596516691\n",
      "GMM score:0.943860977867542 QDA score:0.9460069006143229\n",
      "GMM score:0.9677532165454871 QDA score:0.9507311439678591\n",
      "GMM score:0.9733644276666771 QDA score:0.9473450223068044\n",
      "GMM score:0.9778282693278684 QDA score:0.9644257328699991\n",
      "GMM score:0.980034155034155 QDA score:0.9734630234630235\n",
      "GMM score:0.9735469448584203 QDA score:0.9652493169398908\n",
      "GMM score:0.981302074504844 QDA score:0.9756301096579871\n",
      "GMM score:0.9691130674332258 QDA score:0.9714786201940353\n",
      "GMM score:0.975057317392174 QDA score:0.9684715874994229\n",
      "GMM score:0.984853631422925 QDA score:0.9797430830039526\n",
      "GMM score:0.970279333143526 QDA score:0.9654076112745563\n",
      "GMM score:0.9835619824496354 QDA score:0.9669926461500432\n",
      "GMM score:0.974541083916084 QDA score:0.9669507575757577\n",
      "GMM score:0.9741999412800939 QDA score:0.9654873752201996\n",
      "GMM score:0.9612506109481916 QDA score:0.9544232649071358\n",
      "GMM score:0.9698253313182981 QDA score:0.9562747035573123\n",
      "GMM score:0.9719786476868328 QDA score:0.9565978647686832\n",
      "GMM score:0.9766701757227306 QDA score:0.967859745728399\n",
      "GMM score:0.9809212864250177 QDA score:0.9671508528784648\n",
      "GMM score:0.9813139878148357 QDA score:0.9728424722065198\n",
      "GMM score:0.9528099777460391 QDA score:0.9570365695685389\n",
      "GMM score:0.9666030534351145 QDA score:0.9547447173359885\n",
      "GMM score:0.9678062316880776 QDA score:0.9601504394861393\n",
      "GMM score:0.9596861043362579 QDA score:0.9542934971967946\n",
      "GMM score:0.9681251488922417 QDA score:0.9623838640514571\n",
      "GMM score:0.9870033137749673 QDA score:0.9755115070075701\n",
      "GMM score:0.9814724380318165 QDA score:0.9738068812430634\n",
      "GMM score:0.9834224922174871 QDA score:0.9764106748874181\n",
      "GMM score:0.971694214876033 QDA score:0.9806387741046831\n",
      "GMM score:0.9701490248988103 QDA score:0.9663007481908501\n",
      "GMM score:0.9859036332449712 QDA score:0.9687119912677374\n",
      "GMM score:0.9695682094616221 QDA score:0.9697042442865373\n",
      "GMM score:0.9663800904977377 QDA score:0.9626696832579185\n",
      "GMM score:0.9641714285714286 QDA score:0.9501061224489796\n",
      "GMM score:0.979788723007198 QDA score:0.9736736870167955\n",
      "GMM score:0.9873509433962264 QDA score:0.9787471698113207\n",
      "GMM score:0.9814637482900137 QDA score:0.9706186350509196\n",
      "GMM score:0.9370667975219285 QDA score:0.9410691283812795\n",
      "GMM score:0.9768242645672944 QDA score:0.9633987212387456\n",
      "GMM score:0.98477354948024 QDA score:0.9791867014699822\n",
      "GMM score:0.9848172554939472 QDA score:0.9674137080152118\n",
      "GMM score:0.9694663427372041 QDA score:0.9662187846034344\n",
      "GMM score:0.962718919230326 QDA score:0.9713100587625302\n",
      "GMM score:0.9751051417718084 QDA score:0.9536773240476946\n",
      "GMM score:0.97266685520362 QDA score:0.9688207013574661\n",
      "GMM score:0.9778603596510567 QDA score:0.9541618114823797\n",
      "GMM score:0.9567992828217255 QDA score:0.9476645336795573\n",
      "GMM score:0.9689188395583744 QDA score:0.9750264270613108\n",
      "GMM score:0.9760215265287769 QDA score:0.9614152428057554\n",
      "GMM score:0.9602267337064796 QDA score:0.972646491477722\n",
      "GMM score:0.9707067602411079 QDA score:0.9573536191793452\n",
      "GMM score:0.9799357945425361 QDA score:0.9729935794542536\n",
      "GMM score:0.966817120622568 QDA score:0.9620700389105059\n",
      "GMM score:0.9732188828574371 QDA score:0.9629433484855172\n",
      "GMM score:0.9871717328006978 QDA score:0.9788727441520263\n",
      "GMM score:0.9740606060606061 QDA score:0.964969696969697\n",
      "GMM score:0.9761860884165693 QDA score:0.971394639310359\n",
      "GMM score:0.9725497159090909 QDA score:0.976122159090909\n",
      "GMM score:0.9702273435066957 QDA score:0.9608221737776393\n",
      "GMM score:0.9736346516007535 QDA score:0.9670888767389588\n",
      "GMM score:0.9742705234508513 QDA score:0.9713905943414141\n",
      "GMM score:0.9722762791533188 QDA score:0.9556749797910241\n",
      "GMM score:0.9842660277442887 QDA score:0.9681810551375768\n",
      "GMM score:0.981057442281932 QDA score:0.9759120636671657\n",
      "GMM score:0.9668899146227411 QDA score:0.9533291097233535\n",
      "GMM score:0.9711329506016672 QDA score:0.9634296649476176\n",
      "GMM score:0.952375 QDA score:0.9540500000000001\n",
      "GMM score:0.9794662237955801 QDA score:0.969669157816529\n",
      "GMM score:0.9621645508597141 QDA score:0.9408082918206652\n",
      "GMM score:0.9627299928915045 QDA score:0.9573407614355854\n",
      "GMM score:0.9712505057421184 QDA score:0.9754598362951666\n",
      "GMM score:0.9771035973444495 QDA score:0.9696155627605374\n",
      "GMM score:0.9749566467215548 QDA score:0.9692543236107423\n",
      "GMM score:0.9704016393442623 QDA score:0.9710983606557377\n",
      "GMM score:0.9828558414224233 QDA score:0.9817799139258003\n",
      "GMM score:0.9873848334514528 QDA score:0.9773367981730845\n",
      "GMM score:0.9728850173238508 QDA score:0.9604427050456592\n",
      "GMM score:0.9505104581673307 QDA score:0.9450323705179283\n",
      "GMM score:0.9519709017086788 QDA score:0.9485450854339368\n",
      "GMM score:0.9696504884004884 QDA score:0.9567918192918192\n",
      "GMM score:0.9760209163346614 QDA score:0.9665172642762284\n",
      "GMM score:0.9811340996168582 QDA score:0.9791111111111112\n",
      "GMM score:0.9672208835341366 QDA score:0.9586987951807229\n",
      "GMM score:0.9801864801864801 QDA score:0.9719405594405595\n",
      "GMM score:0.9581828090937402 QDA score:0.9560728744939271\n",
      "GMM score:0.9849130609345563 QDA score:0.9732233855276569\n",
      "GMM score:0.9782128478284104 QDA score:0.9768144083799479\n",
      "GMM score:0.9892477286117398 QDA score:0.9657121151043443\n",
      "GMM score:0.9802230483271375 QDA score:0.9631226765799256\n",
      "GMM score:0.9849376114081996 QDA score:0.9733140225787285\n",
      "GMM score:0.9773351860429211 QDA score:0.9655318820441563\n",
      "GMM score:0.9620895431964135 QDA score:0.965648854961832\n",
      "GMM score:0.9342880957793438 QDA score:0.9557550958551189\n",
      "GMM score:0.9514916666666666 QDA score:0.9491666666666667\n",
      "GMM score:0.9832429931253306 QDA score:0.9741373611845585\n",
      "GMM score:0.9793373216751036 QDA score:0.9714756864549777\n",
      "GMM score:0.9748162284421825 QDA score:0.9651116765620582\n",
      "GMM score:0.961958617144326 QDA score:0.9647538876751061\n",
      "GMM score:0.984475117847969 QDA score:0.9681104807068056\n",
      "GMM score:0.9765663802055898 QDA score:0.9574823532953056\n",
      "GMM score:0.9704804764613377 QDA score:0.9574313246562051\n",
      "GMM score:0.9579437869822486 QDA score:0.9594674556213019\n",
      "GMM score:0.9822984244670991 QDA score:0.9670451034908867\n",
      "GMM score:0.9851721121066763 QDA score:0.9705252360696291\n",
      "GMM score:0.9575020402493445 QDA score:0.9513639283915891\n",
      "GMM score:0.9603581194610087 QDA score:0.9494613382532204\n",
      "GMM score:0.9625009536888685 QDA score:0.9572137026016633\n",
      "GMM score:0.9676153172360223 QDA score:0.9655246500404913\n",
      "GMM score:0.972854775136144 QDA score:0.9555147007618491\n",
      "GMM score:0.9884417132109065 QDA score:0.987350496073054\n",
      "GMM score:0.9802440081748931 QDA score:0.9692512541029293\n",
      "GMM score:0.9785835320697879 QDA score:0.963238985816493\n",
      "GMM score:0.9804088455404244 QDA score:0.9716905901116427\n",
      "GMM score:0.972039497153294 QDA score:0.9622151510395114\n",
      "GMM score:0.9727570541150292 QDA score:0.9637250054084124\n",
      "GMM score:0.9466847319840799 QDA score:0.9689728173427048\n",
      "GMM score:0.9770277341705914 QDA score:0.9626831501831502\n",
      "GMM score:0.9817191852075573 QDA score:0.9671633276284438\n",
      "GMM score:0.9788015085474048 QDA score:0.9581749049429658\n",
      "GMM score:0.9724998398359921 QDA score:0.9777372028957653\n",
      "GMM score:0.9833139497318601 QDA score:0.9645764683078115\n",
      "GMM score:0.9749368007933072 QDA score:0.9699437142976857\n",
      "GMM score:0.9669326185875459 QDA score:0.9403945646076171\n",
      "GMM score:0.9706644601261476 QDA score:0.9629363642040841\n",
      "GMM score:0.9825308560248319 QDA score:0.9713138267355135\n",
      "GMM score:0.9823422053231939 QDA score:0.9697186311787073\n",
      "GMM score:0.9646660716941841 QDA score:0.9651346125241708\n",
      "GMM score:0.9852546478135638 QDA score:0.9848127782141922\n",
      "GMM score:0.9727305915779113 QDA score:0.9669052872176631\n",
      "GMM score:0.9543911051010443 QDA score:0.9461197505822252\n",
      "GMM score:0.9743481781376518 QDA score:0.9686882591093117\n",
      "GMM score:0.9753327279434717 QDA score:0.9757867703396804\n",
      "GMM score:0.9749968998015872 QDA score:0.9628131200396826\n",
      "GMM score:0.958449535192563 QDA score:0.9419488711819389\n",
      "GMM score:0.9623155676001205 QDA score:0.9482685937970491\n",
      "GMM score:0.9700450522414288 QDA score:0.955283253986005\n",
      "GMM score:0.9806570512820513 QDA score:0.9762660256410257\n",
      "GMM score:0.960084797092671 QDA score:0.9587825560266505\n",
      "GMM score:0.9860673631685639 QDA score:0.9828785279900203\n",
      "GMM score:0.9584576083954708 QDA score:0.9414181165423917\n",
      "GMM score:0.9811332464469683 QDA score:0.9730652268354746\n",
      "GMM score:0.9753453400944221 QDA score:0.9628868683336248\n",
      "GMM score:0.9543409806567701 QDA score:0.9544695071010859\n",
      "GMM score:0.9849862757518172 QDA score:0.9623563478418242\n",
      "GMM score:0.9563749921140622 QDA score:0.9474638824048957\n",
      "GMM score:0.9836538314440009 QDA score:0.9786819037128828\n",
      "GMM score:0.982030509960272 QDA score:0.9693627970762466\n",
      "GMM score:0.9785478797410925 QDA score:0.9770355695360232\n",
      "GMM score:0.9820495161404252 QDA score:0.9863495090767818\n",
      "GMM score:0.9786147388059703 QDA score:0.9643501243781095\n",
      "GMM score:0.9762360174195202 QDA score:0.9741952010929895\n",
      "GMM score:0.974612586970272 QDA score:0.967931688804554\n",
      "GMM score:0.9764561115668582 QDA score:0.9666865538071444\n",
      "GMM score:0.9736349924585219 QDA score:0.9650377073906485\n",
      "GMM score:0.9788735726452589 QDA score:0.9750094631253549\n",
      "GMM score:0.9726135615536537 QDA score:0.9607307439104675\n",
      "GMM score:0.9793713862542367 QDA score:0.9718733088381896\n",
      "GMM score:0.9832484732883139 QDA score:0.9846559707117476\n",
      "GMM score:0.9447669062096924 QDA score:0.9508552914440145\n",
      "GMM score:0.9671607225567392 QDA score:0.972425505635325\n",
      "GMM score:0.9650704910063199 QDA score:0.9571301247771836\n",
      "GMM score:0.9753762572498349 QDA score:0.9724689817194039\n",
      "GMM score:0.9819328597954552 QDA score:0.9721329835833652\n",
      "GMM score:0.9859713155609866 QDA score:0.9802874875389909\n",
      "GMM score:0.9569733680416498 QDA score:0.9471282205313042\n",
      "GMM score:0.977777611448759 QDA score:0.9671716415676178\n",
      "GMM score:0.9773184373944831 QDA score:0.954886445380742\n",
      "GMM score:0.932852888807024 QDA score:0.9609888254436053\n",
      "GMM score:0.9623190661478599 QDA score:0.9574941634241245\n",
      "GMM score:0.9711548488008342 QDA score:0.9701511991657977\n",
      "GMM score:0.9802179288606288 QDA score:0.9742194505584088\n",
      "GMM score:0.982996465992932 QDA score:0.9662254324508649\n",
      "GMM score:0.986643487109905 QDA score:0.9787567842605155\n",
      "GMM score:0.9705175865027165 QDA score:0.9658135544752645\n",
      "GMM score:0.9754199487520167 QDA score:0.9726835595204202\n",
      "GMM score:0.9777925405713203 QDA score:0.9742020182847744\n",
      "GMM score:0.9769355963729366 QDA score:0.9591102844299776\n",
      "GMM score:0.9716125954198472 QDA score:0.9639278898582334\n",
      "GMM score:0.9749924585218703 QDA score:0.9723831070889895\n",
      "GMM score:0.9689230861351457 QDA score:0.9632945121403551\n",
      "GMM score:0.9800796812749004 QDA score:0.9657370517928288\n",
      "GMM score:0.9695036647303914 QDA score:0.962843283355129\n",
      "GMM score:0.9790630689383442 QDA score:0.9656802804271623\n",
      "GMM score:0.9681320702657961 QDA score:0.954229130261504\n",
      "GMM score:0.9666084332565711 QDA score:0.949853092988168\n",
      "GMM score:0.9768481959539977 QDA score:0.9701575040560525\n",
      "GMM score:0.9675910918049794 QDA score:0.967291234439834\n",
      "GMM score:0.9724410067757707 QDA score:0.9571522897703156\n",
      "GMM score:0.9778740490278951 QDA score:0.9688644688644689\n",
      "GMM score:0.9778485860473668 QDA score:0.9643677808756395\n",
      "GMM score:0.970809967956054 QDA score:0.9663967727168689\n",
      "GMM score:0.9680226462570769 QDA score:0.9517943264535842\n",
      "GMM score:0.9527922957801006 QDA score:0.9399277326106594\n",
      "GMM score:0.9805875359779751 QDA score:0.9765908522087348\n",
      "GMM score:0.9725683376798995 QDA score:0.9606555265784475\n",
      "GMM score:0.9725093984962406 QDA score:0.9654752114661652\n",
      "GMM score:0.9854799015586547 QDA score:0.9764315012305168\n",
      "GMM score:0.970505776275007 QDA score:0.9754578754578754\n",
      "GMM score:0.977737157855268 QDA score:0.9656136732908386\n",
      "GMM score:0.962875484496124 QDA score:0.9565770348837208\n",
      "GMM score:0.9521350210970464 QDA score:0.9469704641350211\n",
      "GMM score:0.9786095351003472 QDA score:0.9757981200779067\n",
      "GMM score:0.968294132767817 QDA score:0.9697480881691409\n",
      "GMM score:0.963375819751003 QDA score:0.9692750662462436\n",
      "GMM score:0.974322486797584 QDA score:0.9608354678556748\n",
      "GMM score:0.9780929354876754 QDA score:0.9815647482014389\n",
      "GMM score:0.9656116859403531 QDA score:0.967200919726787\n",
      "GMM score:0.9733070983070983 QDA score:0.9681021681021682\n",
      "GMM score:0.9889324456760501 QDA score:0.9822243249636714\n",
      "GMM score:0.9763431013431013 QDA score:0.9727258852258852\n",
      "GMM score:0.9766943194600676 QDA score:0.9758155230596175\n",
      "GMM score:0.9790578623506903 QDA score:0.9717151869279694\n",
      "GMM score:0.9749899181933404 QDA score:0.9715332987671391\n",
      "GMM score:0.9655948004405355 QDA score:0.9562411776567856\n",
      "GMM score:0.9695012472790251 QDA score:0.960881516437072\n",
      "GMM score:0.9602892629272698 QDA score:0.9562330683483591\n",
      "GMM score:0.96105422061753 QDA score:0.966796875\n",
      "GMM score:0.9636069487638614 QDA score:0.9454653975434296\n",
      "GMM score:0.9872539915525866 QDA score:0.980221969265794\n",
      "GMM score:0.9850915485353776 QDA score:0.9616606765490753\n",
      "GMM score:0.961489898989899 QDA score:0.9443241943241943\n",
      "GMM score:0.9922079792596861 QDA score:0.9863171539680254\n",
      "GMM score:0.9776009560034393 QDA score:0.9719028257479707\n",
      "GMM score:0.9841567581812827 QDA score:0.975522036368146\n",
      "GMM score:0.9886580499653018 QDA score:0.9818630002313208\n",
      "GMM score:0.9728920990566039 QDA score:0.9602004716981132\n",
      "GMM score:0.969148028741199 QDA score:0.962309705214764\n",
      "GMM score:0.9687452471482889 QDA score:0.9421368821292776\n",
      "GMM score:0.9734008959389 QDA score:0.9513549239920687\n",
      "GMM score:0.9600014994751837 QDA score:0.9615759484180537\n",
      "GMM score:0.9719377595721681 QDA score:0.9635674460943278\n",
      "GMM score:0.9732005075271766 QDA score:0.9676794348616302\n",
      "GMM score:0.9892239543402334 QDA score:0.9798818752307125\n",
      "GMM score:0.9736078331313389 QDA score:0.9685048159724436\n",
      "GMM score:0.9505999414691249 QDA score:0.9614427860696517\n",
      "GMM score:0.9746204780361757 QDA score:0.9617409560723514\n",
      "GMM score:0.9791596779604159 QDA score:0.9773845465727384\n",
      "GMM score:0.9785927081855582 QDA score:0.9729394240317776\n",
      "GMM score:0.9753672631065933 QDA score:0.9710297291652161\n",
      "GMM score:0.9678972332015809 QDA score:0.9508458498023715\n",
      "GMM score:0.9678133460742157 QDA score:0.9511626055104315\n",
      "GMM score:0.9796342713911359 QDA score:0.9705622650108238\n",
      "GMM score:0.9732307692307692 QDA score:0.9602307692307692\n",
      "GMM score:0.9589853755267289 QDA score:0.9504585639923986\n",
      "GMM score:0.9576965140123035 QDA score:0.9488174982911824\n",
      "GMM score:0.9641953124999999 QDA score:0.9431796875\n",
      "GMM score:0.9590079934412791 QDA score:0.9547892327662771\n",
      "GMM score:0.9779924484638105 QDA score:0.9665814073871076\n",
      "GMM score:0.9650631732343795 QDA score:0.9585805928218379\n",
      "GMM score:0.967976369092273 QDA score:0.9611465366341585\n",
      "GMM score:0.9867739463601533 QDA score:0.9804750957854407\n",
      "GMM score:0.960740773637696 QDA score:0.9545602581753045\n",
      "GMM score:0.9627557265256164 QDA score:0.9561476365331933\n",
      "GMM score:0.9876718338695525 QDA score:0.9697499268792045\n",
      "GMM score:0.961024011299435 QDA score:0.9566666666666666\n",
      "GMM score:0.9569158310993942 QDA score:0.9652838460285252\n",
      "GMM score:0.9712804685026907 QDA score:0.9662155745489078\n",
      "GMM score:0.9704125784630386 QDA score:0.9596867572673533\n",
      "GMM score:0.9765727187791966 QDA score:0.9602616007474307\n",
      "GMM score:0.956263433536161 QDA score:0.9398555989465082\n",
      "GMM score:0.9717607410794424 QDA score:0.96623143490999\n",
      "GMM score:0.9771930922287573 QDA score:0.9712332624202227\n",
      "GMM score:0.9857376104494814 QDA score:0.9781913725920641\n",
      "GMM score:0.9653983656792645 QDA score:0.9690018159119284\n",
      "GMM score:0.9698092557848654 QDA score:0.9640400250156347\n",
      "GMM score:0.9639065332297521 QDA score:0.9521089430151259\n",
      "GMM score:0.9762280132307026 QDA score:0.9709728275989985\n",
      "GMM score:0.9752787516523939 QDA score:0.9704724409448818\n",
      "GMM score:0.9752104377104378 QDA score:0.9699284511784512\n",
      "GMM score:0.9727233420801527 QDA score:0.9655295801526718\n",
      "GMM score:0.9677433894230769 QDA score:0.9689227764423076\n",
      "GMM score:0.9684173472261335 QDA score:0.9634328358208956\n",
      "GMM score:0.9746263178967036 QDA score:0.9723074869878554\n",
      "GMM score:0.9729959711030842 QDA score:0.9557950125034731\n",
      "GMM score:0.9711382844812083 QDA score:0.9670098303662412\n",
      "GMM score:0.9736891502940808 QDA score:0.9662902014766613\n",
      "GMM score:0.9732740154885483 QDA score:0.9600098863074642\n",
      "GMM score:0.9563012445693007 QDA score:0.961062293796753\n",
      "GMM score:0.9829448294482944 QDA score:0.973359733597336\n",
      "GMM score:0.972860433983998 QDA score:0.9729616138974503\n",
      "GMM score:0.984826880977071 QDA score:0.9722822329761492\n",
      "GMM score:0.9719085550887021 QDA score:0.9584135737628385\n",
      "GMM score:0.9703567291412957 QDA score:0.9576736863991446\n",
      "GMM score:0.952656281885586 QDA score:0.9466362832460375\n",
      "GMM score:0.9586681631126075 QDA score:0.9636887392442948\n",
      "GMM score:0.9799956068783734 QDA score:0.9768027488389607\n",
      "GMM score:0.9706849717348212 QDA score:0.965641289185816\n",
      "GMM score:0.9768382522569632 QDA score:0.9708632595622952\n",
      "GMM score:0.9789395037800891 QDA score:0.9690121465875634\n",
      "GMM score:0.9739139973672664 QDA score:0.9614889571449465\n",
      "GMM score:0.9722289977760241 QDA score:0.9513738431738288\n",
      "GMM score:0.9573840725806451 QDA score:0.9631468413978495\n",
      "GMM score:0.9684489738936201 QDA score:0.960801650456823\n",
      "GMM score:0.9601890756302521 QDA score:0.9534138655462185\n",
      "GMM score:0.9825405337202702 QDA score:0.9830136899880134\n",
      "GMM score:0.9781163871170958 QDA score:0.9566028821167021\n",
      "GMM score:0.9600361056970317 QDA score:0.9644215100488865\n",
      "GMM score:0.9715366177566158 QDA score:0.9627182327600168\n",
      "GMM score:0.9621249042679105 QDA score:0.9500870291721786\n",
      "GMM score:0.9704405673402787 QDA score:0.9590968997113092\n",
      "GMM score:0.9864341085271318 QDA score:0.976829685362517\n",
      "GMM score:0.9819642477122792 QDA score:0.9675614872465266\n",
      "GMM score:0.975610864526684 QDA score:0.9637192674170241\n",
      "GMM score:0.9544333333333334 QDA score:0.9591166666666667\n",
      "GMM score:0.9757408864411224 QDA score:0.9622672436401783\n",
      "GMM score:0.9765726227795193 QDA score:0.9731870428422154\n",
      "GMM score:0.9663832720588236 QDA score:0.9590839460784314\n",
      "GMM score:0.9676933765632237 QDA score:0.953419793114096\n",
      "GMM score:0.976516187870497 QDA score:0.9631858945128439\n",
      "GMM score:0.9748038000826105 QDA score:0.9668917090401515\n",
      "GMM score:0.9800031753592126 QDA score:0.9724061284432801\n",
      "GMM score:0.9715896561356053 QDA score:0.9648417400508666\n",
      "GMM score:0.9880873956960914 QDA score:0.978542215634607\n",
      "GMM score:0.9789809095228779 QDA score:0.9748721245492914\n",
      "GMM score:0.9652026813381395 QDA score:0.9651394422310757\n",
      "GMM score:0.9896798535205016 QDA score:0.9822934583587639\n",
      "GMM score:0.9715092253070252 QDA score:0.9718002444560851\n",
      "GMM score:0.9704215923192476 QDA score:0.9644128404415127\n",
      "GMM score:0.976199752680704 QDA score:0.9692544847796994\n",
      "GMM score:0.9865508365508366 QDA score:0.9744816244816245\n",
      "GMM score:0.9602679239634785 QDA score:0.9489522526567878\n",
      "GMM score:0.9519203936256151 QDA score:0.9643386942792099\n",
      "GMM score:0.9729971021280333 QDA score:0.9626862394988731\n",
      "GMM score:0.9857939677730341 QDA score:0.97134003580774\n",
      "GMM score:0.9622248062015504 QDA score:0.9676046511627908\n",
      "GMM score:0.9672582440110116 QDA score:0.9582967258244011\n",
      "GMM score:0.9807950835413866 QDA score:0.9741613853146407\n",
      "GMM score:0.9852862453531599 QDA score:0.9739925650557621\n",
      "GMM score:0.9682410298211347 QDA score:0.9509543070700235\n",
      "GMM score:0.9707280080889787 QDA score:0.9423744523087293\n",
      "GMM score:0.9803102040816326 QDA score:0.9725714285714285\n",
      "GMM score:0.9679592598222799 QDA score:0.9660521551664571\n",
      "GMM score:0.9790398660986 QDA score:0.9835057821059039\n",
      "GMM score:0.963036351715597 QDA score:0.9603117942740584\n",
      "GMM score:0.979296825194441 QDA score:0.9683794466403162\n",
      "GMM score:0.9794848686082913 QDA score:0.9740695063719444\n",
      "GMM score:0.950574573422762 QDA score:0.9521113112991869\n",
      "GMM score:0.9679932939718638 QDA score:0.9708287776076974\n",
      "GMM score:0.9609843172255514 QDA score:0.9619246461813082\n",
      "GMM score:0.9672745946282406 QDA score:0.9673679624039091\n",
      "GMM score:0.9729364113729508 QDA score:0.9592805455942623\n",
      "GMM score:0.9759863752483678 QDA score:0.9749219415271075\n",
      "GMM score:0.963513801070039 QDA score:0.9608159046692606\n",
      "GMM score:0.9678521925403226 QDA score:0.98486328125\n",
      "GMM score:0.9745310815666548 QDA score:0.9680488681279195\n",
      "GMM score:0.9732817052143409 QDA score:0.9650544027587847\n",
      "GMM score:0.9828265064741035 QDA score:0.9718158615537847\n",
      "GMM score:0.9939979045053136 QDA score:0.9872923215087561\n",
      "GMM score:0.973891900510204 QDA score:0.9739477040816327\n",
      "GMM score:0.963608481753643 QDA score:0.961864802590609\n",
      "GMM score:0.9643368786629044 QDA score:0.9724332537443022\n",
      "GMM score:0.9682221283783785 QDA score:0.9565033783783783\n",
      "GMM score:0.9753496234824036 QDA score:0.9628707545719993\n",
      "GMM score:0.9793790481554492 QDA score:0.9724655026753027\n",
      "GMM score:0.9759687499999999 QDA score:0.966546875\n",
      "GMM score:0.9879449454200284 QDA score:0.9805726941939567\n",
      "GMM score:0.9796566639632331 QDA score:0.977471388663603\n",
      "GMM score:0.9768757687576876 QDA score:0.9575722632226322\n",
      "GMM score:0.9565376805054151 QDA score:0.9530685920577617\n",
      "GMM score:0.9771148084401096 QDA score:0.9743736852170587\n",
      "GMM score:0.9737594737594737 QDA score:0.9552474552474554\n",
      "GMM score:0.9661182111381315 QDA score:0.9551922181404252\n",
      "GMM score:0.9485179786200195 QDA score:0.9527939747327502\n",
      "GMM score:0.9787599728399252 QDA score:0.9610069031856504\n",
      "GMM score:0.9774371104944731 QDA score:0.9726000394244037\n",
      "GMM score:0.9704190516571267 QDA score:0.9694862553883118\n",
      "GMM score:0.9705737109658679 QDA score:0.9483587509077704\n",
      "GMM score:0.9738322972700637 QDA score:0.9736617731408995\n",
      "GMM score:0.9623019315290308 QDA score:0.9558032616238722\n",
      "GMM score:0.9624164151724954 QDA score:0.9626457186815789\n",
      "GMM score:0.9693477390956382 QDA score:0.9507803121248499\n",
      "GMM score:0.9639487441030217 QDA score:0.9590877215351269\n",
      "GMM score:0.9718096419709323 QDA score:0.9525168380007092\n",
      "GMM score:0.9786457422626333 QDA score:0.9594480387014045\n",
      "GMM score:0.966862014762165 QDA score:0.9709711591033351\n",
      "GMM score:0.9774803767660911 QDA score:0.9627943485086342\n",
      "GMM score:0.985707605514828 QDA score:0.964793193954204\n",
      "GMM score:0.9652642843062713 QDA score:0.9657852496409564\n",
      "GMM score:0.9764908939411975 QDA score:0.9690810617783597\n",
      "GMM score:0.9444591242054579 QDA score:0.9334566433258467\n",
      "GMM score:0.9531085604973696 QDA score:0.9594771241830066\n",
      "GMM score:0.952041462973022 QDA score:0.9440521455730583\n",
      "GMM score:0.9712876477316049 QDA score:0.9580235735163299\n",
      "\n",
      "GMM scores CV = 0.97305\n",
      "QDA scores CV = 0.96543\n",
      "Agged scores CV = 0.97392\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# INITIALIZE VARIABLES\n",
    "cols = [c for c in train.columns if c not in ['id', 'target']]\n",
    "cols.remove('wheezy-copper-turtle-magic')\n",
    "oof_gmm = np.zeros(len(train))\n",
    "preds_gmm = np.zeros(len(test))\n",
    "\n",
    "oof_qda = np.zeros(len(train))\n",
    "oof = np.zeros(len(train))\n",
    "\n",
    "preds_qda = np.zeros(len(test))\n",
    "preds = np.zeros(len(test))\n",
    "\n",
    "feature_wise_score = []\n",
    "\n",
    "# BUILD 512 SEPARATE MODELS\n",
    "for i in tqdm(range(512)):\n",
    "    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n",
    "    train2 = train[train['wheezy-copper-turtle-magic']==i]\n",
    "    test2 = test[test['wheezy-copper-turtle-magic']==i]\n",
    "    idx1 = train2.index; idx2 = test2.index\n",
    "    train2.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "#     low, high = low_high_var_feats(train2)\n",
    "    \n",
    "    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n",
    "    sel = VarianceThreshold(threshold=2.5).fit(np.vstack((train2[cols], test2[cols])))\n",
    "    train3 = sel.transform(train2[cols])\n",
    "    test3 = sel.transform(test2[cols])\n",
    "#     train3 = train2[high].values\n",
    "#     test3 = test2[high].values\n",
    "    \n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit(np.vstack((train3, test3)))\n",
    "#     train3 = scaler.transform(train3)\n",
    "#     test3 = scaler.transform(test3)\n",
    "\n",
    "    # STRATIFIED K-FOLD\n",
    "    skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n",
    "    for train_index, test_index in skf.split(train3, train2['target']):\n",
    "\n",
    "        # GMM\n",
    "#         ms, ps = get_mean_cov(train3[train_index,:],train2.loc[train_index]['target'].values)\n",
    "#         display()\n",
    "        label0_indices = np.where(train2[\"target\"].values==0)[0]\n",
    "        label1_indices = np.where(train2[\"target\"].values==1)[0]\n",
    "#         print(label0_indices, label1_indices)\n",
    "#         print(train_index)\n",
    "#         print(train3.shape)\n",
    "        ms, ps = cluster_analysis(train3[label0_indices], train3[label1_indices])\n",
    "#         print(ms)\n",
    "        \n",
    "        gm = GaussianMixture(n_components=6, covariance_type='full', \n",
    "                             tol=0.001,reg_covar=0.001, max_iter=100, n_init=1,\n",
    "                             means_init=ms, precisions_init=ps, random_state=1)\n",
    "        \n",
    "        gm.fit(np.concatenate([train3[train_index,:],test3],axis = 0))\n",
    "#         oof_gmm[idx1[test_index]] = gm.predict_proba(train3[test_index,:])[:,0]\n",
    "        oof_gmm[idx1[test_index]] = np.sum(gm.predict_proba(train3[test_index,:])[:,3:], axis=1)\n",
    "#         preds_gmm[idx2] += gm.predict_proba(test3)[:,0] / skf.n_splits\n",
    "        preds_gmm[idx2] += np.sum(gm.predict_proba(test3)[:,3:], axis=1) / skf.n_splits\n",
    "\n",
    "        \n",
    "        # QDA\n",
    "        clf_qda = QuadraticDiscriminantAnalysis(reg_param=best_reg)\n",
    "        clf_qda.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "        oof_qda[idx1[test_index]] = clf_qda.predict_proba(train3[test_index,:])[:,1]\n",
    "        preds_qda[idx2] += clf_qda.predict_proba(test3)[:,1] / skf.n_splits\n",
    "    \n",
    "    gmm_feature_score = roc_auc_score(train[\"target\"][idx1], oof_gmm[idx1])\n",
    "    qda_feature_score = roc_auc_score(train[\"target\"][idx1], oof_qda[idx1])\n",
    "    print(\"GMM score:{} QDA score:{}\".format(gmm_feature_score, qda_feature_score))\n",
    "    \n",
    "    if gmm_feature_score < qda_feature_score:\n",
    "        oof[idx1] = oof_qda[idx1]\n",
    "        preds[idx2] = preds_qda[idx2]\n",
    "    else:\n",
    "        oof[idx1] = oof_gmm[idx1]\n",
    "        preds[idx2] = preds_gmm[idx2]\n",
    "\n",
    "\n",
    "# PRINT CV AUC\n",
    "gmm_auc = roc_auc_score(train['target'],oof_gmm)\n",
    "qda_auc = roc_auc_score(train['target'],oof_qda)\n",
    "auc = roc_auc_score(train['target'],oof)\n",
    "\n",
    "print('GMM scores CV = {}'.format(round(gmm_auc,5)))\n",
    "print('QDA scores CV = {}'.format(round(qda_auc,5)))\n",
    "print('Agged scores CV = {}'.format(round(auc,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "# from sklearn.mixture import GaussianMixture\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# # INITIALIZE VARIABLES\n",
    "# cols = [c for c in train.columns if c not in ['id', 'target']]\n",
    "# cols.remove('wheezy-copper-turtle-magic')\n",
    "# oof_gmm = np.zeros(len(train))\n",
    "# preds_gmm = np.zeros(len(test))\n",
    "\n",
    "# oof_qda = np.zeros(len(train))\n",
    "# oof = np.zeros(len(train))\n",
    "\n",
    "# preds_qda = np.zeros(len(test))\n",
    "\n",
    "# feature_wise_score = []\n",
    "\n",
    "# # BUILD 512 SEPARATE MODELS\n",
    "# for i in tqdm(range(512)):\n",
    "#     # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n",
    "#     train2 = train[train['wheezy-copper-turtle-magic']==i]\n",
    "#     test2 = test[test['wheezy-copper-turtle-magic']==i]\n",
    "#     idx1 = train2.index; idx2 = test2.index\n",
    "#     train2.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "# #     low, high = low_high_var_feats(train2)\n",
    "    \n",
    "#     # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n",
    "#     sel = VarianceThreshold(threshold=2.5).fit(np.vstack((train2[cols], test2[cols])))\n",
    "#     train3 = sel.transform(train2[cols])\n",
    "#     test3 = sel.transform(test2[cols])\n",
    "\n",
    "# #     train3 = train2[high].values\n",
    "# #     test3 = test2[high].values\n",
    "    \n",
    "# #     pca = PCA(n_components=10)\n",
    "# #     train3 = pca.fit_transform(train3)\n",
    "# #     test3 = pca.fit_transform(test3)\n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit(np.vstack((train3, test3)))\n",
    "#     train3 = scaler.transform(train3)\n",
    "#     test3 = scaler.transform(test3)\n",
    "\n",
    "#     # STRATIFIED K-FOLD\n",
    "#     skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n",
    "#     for train_index, test_index in skf.split(train3, train2['target']):\n",
    "\n",
    "#         # GMM\n",
    "#         ms, ps = get_mean_cov(train3[train_index,:],train2.loc[train_index]['target'].values)\n",
    "#         gm = GaussianMixture(n_components=6, init_params='random', covariance_type='full', \n",
    "#                              tol=0.001,reg_covar=0.001, max_iter=100, n_init=1, means_init=ms, precisions_init=ps)\n",
    "        \n",
    "#         gm.fit(np.concatenate([train3[train_index,:],test3],axis = 0))\n",
    "# #         oof_gmm[idx1[test_index]] = gm.predict_proba(train3[test_index,:])[:,0]\n",
    "#         oof_gmm[idx1[test_index]] = np.sum(gm.predict_proba(train3[test_index,:])[:,:3], axis=1)\n",
    "# #         preds_gmm[idx2] += gm.predict_proba(test3)[:,0] / skf.n_splits\n",
    "#         preds_gmm[idx2] += np.sum(gm.predict_proba(test3)[:,:3], axis=1) / skf.n_splits\n",
    "\n",
    "        \n",
    "#         # QDA\n",
    "#         clf_qda = QuadraticDiscriminantAnalysis(reg_param=best_reg)\n",
    "#         clf_qda.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "#         oof_qda[idx1[test_index]] = clf_qda.predict_proba(train3[test_index,:])[:,1]\n",
    "#         preds_qda[idx2] += clf_qda.predict_proba(test3)[:,1] / skf.n_splits\n",
    "    \n",
    "#     gmm_feature_score = roc_auc_score(train[\"target\"][idx1], oof_gmm[idx1])\n",
    "#     qda_feature_score = roc_auc_score(train[\"target\"][idx1], oof_qda[idx1])\n",
    "#     print(\"GMM score:{} QDA score:{}\".format(gmm_feature_score, qda_feature_score))\n",
    "    \n",
    "#     if gmm_feature_score < qda_feature_score:\n",
    "#         oof[idx1] = oof_qda[idx1]\n",
    "#     else:\n",
    "#         oof[idx1] = oof_gmm[idx1]\n",
    "\n",
    "\n",
    "# # PRINT CV AUC\n",
    "# gmm_auc = roc_auc_score(train['target'],oof_gmm)\n",
    "# qda_auc = roc_auc_score(train['target'],oof_qda)\n",
    "# auc = roc_auc_score(train['target'],oof)\n",
    "\n",
    "# print('GMM scores CV = {}'.format(round(gmm_auc,5)))\n",
    "# print('QDA scores CV = {}'.format(round(qda_auc,5)))\n",
    "# print('Agged scores CV = {}'.format(round(auc,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cand = np.arange(0, 1, 0.01)\n",
    "# scores = []\n",
    "# for alpha in cand:\n",
    "#     score = roc_auc_score(train['target'],alpha*oof_qda+(1-alpha)*oof_gmm)\n",
    "# #     print(\"alpha: {} blending AUC: {}\".format(alpha, score))\n",
    "#     scores.append(score)\n",
    "\n",
    "# alpha = cand[np.argmax(scores)]\n",
    "# print(\"best alpha: {} AUC: {}\".format(alpha, np.max(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = alpha*preds_qda+(1-alpha)*preds_gmm\n",
    "# oof = alpha*oof_qda+(1-alpha)*oof_gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # INITIALIZE VARIABLES\n",
    "# cols = [c for c in train.columns if c not in ['id', 'target']]\n",
    "# cols.remove('wheezy-copper-turtle-magic')\n",
    "# oof_svm = np.zeros(len(train))\n",
    "# preds = np.zeros(len(test))\n",
    "\n",
    "# # BUILD 512 SEPARATE MODELS\n",
    "# for i in range(512):\n",
    "#     # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n",
    "#     train2 = train[train['wheezy-copper-turtle-magic']==i]\n",
    "#     test2 = test[test['wheezy-copper-turtle-magic']==i]\n",
    "#     idx1 = train2.index; idx2 = test2.index\n",
    "#     train2.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "#     # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n",
    "#     sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n",
    "#     train3 = sel.transform(train2[cols])\n",
    "#     test3 = sel.transform(test2[cols])\n",
    "    \n",
    "#     # STRATIFIED K-FOLD\n",
    "#     skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n",
    "#     for train_index, test_index in skf.split(train3, train2['target']):\n",
    "        \n",
    "#         # MODEL AND PREDICT WITH QDA\n",
    "#         clf_svm = NuSVC(probability=True, kernel='poly', degree=4, random_state=4, nu=0.59, coef0=0.053, gamma=\"scale\")\n",
    "#         clf_svm.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "#         oof_svm[idx1[test_index]] = clf_svm.predict_proba(train3[test_index,:])[:,1]\n",
    "#         preds[idx2] += clf_svm.predict_proba(test3)[:,1] / skf.n_splits\n",
    "       \n",
    "#     #if i%64==0: print(i)\n",
    "        \n",
    "# # PRINT CV AUC\n",
    "# auc = roc_auc_score(train['target'],oof_svm)\n",
    "# print('QDA scores CV =',round(auc,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check inversed labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def BCE(y_true, y_pred):\n",
    "#     ent = []\n",
    "#     eps = 1e-10\n",
    "#     for label, pred in zip(y_true, y_pred):\n",
    "#         pred = max(eps, min(1-eps, pred))\n",
    "#         ent.append(-(label*np.log(pred) + (1-label)*np.log(1-pred)))\n",
    "#     return np.asarray(ent)\n",
    "    \n",
    "# oof_log_loss = BCE(train[\"target\"], oof)\n",
    "# print(oof_log_loss.shape)\n",
    "\n",
    "# fig = plt.figure(figsize=(10,8))\n",
    "# plt.hist(oof_log_loss, bins=100)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_data_idx = np.where(oof_log_loss < 20)[0]\n",
    "# inversed_data_idx = np.where(oof_log_loss > 20)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(clean_data_idx), len(inversed_data_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Inverse labels of inversed data in train, then fit QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # INITIALIZE VARIABLES\n",
    "# cols = [c for c in train.columns if c not in ['id', 'target']]\n",
    "# cols.remove('wheezy-copper-turtle-magic')\n",
    "\n",
    "# # train_cleaned = train.loc[clean_data_idx, :].reset_index(drop=True)\n",
    "# # print(\"clean train df {}==>{}\".format(len(train), len(train_cleaned)))\n",
    "# train_modified = train.copy()\n",
    "# train_modified.loc[inversed_data_idx][\"target\"] = train_modified.loc[inversed_data_idx][\"target\"].map({0 : 1, 1: 0})\n",
    "\n",
    "# oof_qda = np.zeros(len(train_modified))\n",
    "# preds_qda = np.zeros(len(test))\n",
    "\n",
    "\n",
    "# # BUILD 512 SEPARATE MODELS\n",
    "# for i in range(512):\n",
    "#     # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n",
    "#     train2 = train_modified[train_modified['wheezy-copper-turtle-magic']==i]\n",
    "#     test2 = test[test['wheezy-copper-turtle-magic']==i]\n",
    "#     idx1 = train2.index; idx2 = test2.index\n",
    "#     train2.reset_index(drop=True,inplace=True)\n",
    "\n",
    "#     # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n",
    "#     sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n",
    "#     train3 = sel.transform(train2[cols])\n",
    "#     test3 = sel.transform(test2[cols])\n",
    "    \n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit(np.vstack((train3, test3)))\n",
    "#     train3 = scaler.transform(train3)\n",
    "#     test3 = scaler.transform(test3)\n",
    "\n",
    "#     # STRATIFIED K-FOLD\n",
    "#     skf = StratifiedKFold(n_splits=15, random_state=42, shuffle=True)\n",
    "#     for train_index, test_index in skf.split(train3, train2['target']):\n",
    "\n",
    "#         # MODEL AND PREDICT WITH QDA\n",
    "#         clf_qda = QuadraticDiscriminantAnalysis(reg_param=0.6)\n",
    "#         clf_qda.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "#         oof_qda[idx1[test_index]] = clf_qda.predict_proba(train3[test_index,:])[:,1]\n",
    "#         preds_qda[idx2] += clf_qda.predict_proba(test3)[:,1] / skf.n_splits\n",
    "        \n",
    "    \n",
    "# # PRINT CV AUC\n",
    "# auc = roc_auc_score(train_modified['target'],oof_qda)\n",
    "# print('QDA scores CV = {}'.format(round(auc,5)))\n",
    "# auc = roc_auc_score(train['target'],oof_qda)\n",
    "# print('QDA scores CV = {}'.format(round(auc,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 & 4 - Add pseudo label data and build second model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # INITIALIZE VARIABLES\n",
    "# test['target'] = preds\n",
    "# oof_qda = np.zeros(len(train))\n",
    "# # oof_gmm = np.zeros(len(train))\n",
    "# oof = np.zeros(len(train))\n",
    "\n",
    "# preds_qda = np.zeros(len(test))\n",
    "# # preds_gmm = np.zeros(len(test))\n",
    "# preds = np.zeros(len(test))\n",
    "\n",
    "\n",
    "# # BUILD 512 SEPARATE MODELS\n",
    "# for k in range(512):\n",
    "#     # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n",
    "#     train2 = train[train['wheezy-copper-turtle-magic']==k] \n",
    "#     train2p = train2.copy(); idx1 = train2.index \n",
    "#     test2 = test[test['wheezy-copper-turtle-magic']==k]\n",
    "    \n",
    "#     # ADD PSEUDO LABELED DATA\n",
    "#     test2p = test2[ (test2['target']<=0.01) | (test2['target']>=0.99) ].copy()\n",
    "#     test2p.loc[ test2p['target']>=0.5, 'target' ] = 1\n",
    "#     test2p.loc[ test2p['target']<0.5, 'target' ] = 0 \n",
    "#     train2p = pd.concat([train2p,test2p],axis=0)\n",
    "#     train2p.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "#     # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n",
    "#     sel = VarianceThreshold(threshold=1.5).fit(train2p[cols])     \n",
    "#     train3p = sel.transform(train2p[cols])\n",
    "#     train3 = sel.transform(train2[cols])\n",
    "#     test3 = sel.transform(test2[cols])\n",
    "    \n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit(np.vstack((train3, test3)))\n",
    "#     train3 = scaler.transform(train3)\n",
    "#     train3p = scaler.transform(train3p)\n",
    "#     test3 = scaler.transform(test3)\n",
    "    \n",
    "        \n",
    "#     # STRATIFIED K FOLD\n",
    "#     skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n",
    "#     for train_index, test_index in skf.split(train3p, train2p['target']):\n",
    "#         test_index3 = test_index[ test_index<len(train3) ] # ignore pseudo in oof\n",
    "        \n",
    "#         # MODEL AND PREDICT WITH QDA\n",
    "#         clf = QuadraticDiscriminantAnalysis(reg_param=0.6)\n",
    "#         clf.fit(train3p[train_index,:],train2p.loc[train_index]['target'])\n",
    "#         oof_qda[idx1[test_index3]] = clf.predict_proba(train3[test_index3,:])[:,1]\n",
    "#         preds_qda[test2.index] += clf.predict_proba(test3)[:,1] / skf.n_splits\n",
    "                \n",
    "# # PRINT CV AUC\n",
    "# auc = roc_auc_score(train['target'],oof_qda)\n",
    "# print('Pseudo Labeled QDA scores CV =',round(auc,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GMM\n",
    "# # INITIALIZE VARIABLES\n",
    "# test['target'] = preds\n",
    "# oof_gmm = np.zeros(len(train))\n",
    "# preds_gmm = np.zeros(len(test))\n",
    "\n",
    "# # BUILD 512 SEPARATE MODELS\n",
    "# for k in range(512):\n",
    "#     # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n",
    "#     train2 = train[train['wheezy-copper-turtle-magic']==k] \n",
    "#     train2p = train2.copy(); idx1 = train2.index \n",
    "#     test2 = test[test['wheezy-copper-turtle-magic']==k]\n",
    "    \n",
    "#     # ADD PSEUDO LABELED DATA\n",
    "#     test2p = test2[ (test2['target']<=0.005) | (test2['target']>=0.995) ].copy()\n",
    "#     test2p.loc[ test2p['target']>=0.5, 'target' ] = 1\n",
    "#     test2p.loc[ test2p['target']<0.5, 'target' ] = 0 \n",
    "#     train2p = pd.concat([train2p,test2p],axis=0)\n",
    "#     train2p.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "#     # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n",
    "#     sel = VarianceThreshold(threshold=1.5).fit(train2p[cols])     \n",
    "#     train3p = sel.transform(train2p[cols])\n",
    "#     train3 = sel.transform(train2[cols])\n",
    "#     test3 = sel.transform(test2[cols])\n",
    "        \n",
    "#     # STRATIFIED K FOLD\n",
    "#     skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n",
    "#     for train_index, test_index in skf.split(train3p, train2p['target']):\n",
    "#         test_index3 = test_index[ test_index<len(train3) ] # ignore pseudo in oof\n",
    "        \n",
    "#         # MODEL AND PREDICT WITH GMM\n",
    "#         ms, ps = get_mean_cov(train3p[train_index,:],train2p.loc[train_index]['target'].values)\n",
    "        \n",
    "#         gm = GaussianMixture(n_components=2, init_params='random', covariance_type='full', tol=0.001,reg_covar=0.001, max_iter=100, n_init=1,means_init=ms, precisions_init=ps)\n",
    "#         gm.fit(np.concatenate([train3p[train_index,:],test3],axis = 0))\n",
    "#         oof_gmm[idx1[test_index3]] = gm.predict_proba(train3[test_index3,:])[:,0]\n",
    "#         preds_gmm[test2.index] += gm.predict_proba(test3)[:,0] / skf.n_splits\n",
    "       \n",
    "#     #if k%64==0: print(k)\n",
    "        \n",
    "# # PRINT CV AUC\n",
    "# auc = roc_auc_score(train['target'],oof_gmm)\n",
    "# print('Pseudo Labeled QDA scores CV =',round(auc,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# cand = np.arange(0,1,0.01)\n",
    "# scores = []\n",
    "# for alpha in np.arange(0,1,0.01):\n",
    "#     score = roc_auc_score(train['target'],alpha*oof_qda+(1-alpha)*oof_gmm)\n",
    "#     print(\"alpha: {} blending AUC: {}\".format(alpha, score))\n",
    "#     scores.append(score)\n",
    "\n",
    "# alpha = cand[np.argmax(scores)]\n",
    "# print(\"best alpha: \", alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = alpha*preds_qda+(1-alpha)*preds_gmm\n",
    "# oof = alpha*oof_qda+(1-alpha)*oof_gmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub = pd.read_csv('../input/sample_submission.csv')\n",
    "sub['target'] = preds\n",
    "sub.to_csv('submission.csv',index=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(preds,bins=100)\n",
    "plt.title('Final Test.csv predictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In this kernel, we learned what pseudo labeling is, why it works, and how to deploy it. Using it on the data from Instant Gratification competition we observed it increase CV by an impressive 0.005! Pseudo labeling QDA achieved CV 0.970 and LB 0.969. Without pseudo labeling, QDA achieved CV 0.965 and LB 0.965.\n",
    "\n",
    "When you run your kernel locally, it will only pseudo label the public test data (because that is all that `test.csv` contains). When you submit this solution to Kaggle, your submission will load the full `test.csv` and pseudo label both the public and private test data set. Thus you will approximately double your amount of training data for your submissions!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
